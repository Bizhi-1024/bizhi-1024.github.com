{"meta":{"title":"Bizhi-1024","subtitle":"","description":"","author":"毕之","url":"https://bizhi-1024.github.io","root":"/"},"pages":[{"title":"about","date":"2021-04-24T12:20:54.000Z","updated":"2021-04-24T12:22:45.197Z","comments":true,"path":"about/index.html","permalink":"https://bizhi-1024.github.io/about/index.html","excerpt":"","text":""},{"title":"links","date":"2021-04-24T14:48:35.000Z","updated":"2021-04-24T14:48:35.510Z","comments":true,"path":"links/index.html","permalink":"https://bizhi-1024.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-04-25T08:27:30.993Z","updated":"2021-04-25T08:27:30.993Z","comments":false,"path":"repository/index.html","permalink":"https://bizhi-1024.github.io/repository/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-04-24T12:21:40.000Z","updated":"2021-04-24T12:23:12.223Z","comments":true,"path":"categories/index.html","permalink":"https://bizhi-1024.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2021-04-24T12:20:43.000Z","updated":"2021-04-24T12:23:27.974Z","comments":true,"path":"tags/index.html","permalink":"https://bizhi-1024.github.io/tags/index.html","excerpt":"","text":""},{"title":"books","date":"2021-04-24T14:48:21.000Z","updated":"2021-04-24T14:48:21.822Z","comments":true,"path":"books/index.html","permalink":"https://bizhi-1024.github.io/books/index.html","excerpt":"","text":""}],"posts":[{"title":"ElasticSearch教程","slug":"ElasticSearch第一天","date":"2022-03-06T14:44:29.772Z","updated":"2022-03-06T14:45:21.825Z","comments":true,"path":"2022/03/06/ElasticSearch第一天/","link":"","permalink":"https://bizhi-1024.github.io/2022/03/06/ElasticSearch%E7%AC%AC%E4%B8%80%E5%A4%A9/","excerpt":"","text":"ElasticSearch第一天 学习目标： 能够理解ElasticSearch的作用 能够安装ElasticSearch服务 能够理解ElasticSearch的相关概念 能够使用Postman发送Restful请求操作ElasticSearch 能够理解分词器的作用 能够使用ElasticSearch集成IK分词器 能够完成es集群搭建 第一章 ElasticSearch简介 1.1 什么是ElasticSearch Elaticsearch，简称为es， es是一个开源的高扩展的分布式全文检索引擎，它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 1.2 ElasticSearch的使用案例 2013年初，GitHub抛弃了Solr，采取ElasticSearch 来做PB级的搜索。 “GitHub使用ElasticSearch搜索20TB的数据，包括13亿文件和1300亿行代码” 维基百科：启动以elasticsearch为基础的核心搜索架构 SoundCloud：“SoundCloud使用ElasticSearch为1.8亿用户提供即时而精准的音乐搜索服务” 百度：百度目前广泛使用ElasticSearch作为文本数据分析，采集百度所有服务器上的各类指标数据及用户自定义数据，通过对各种数据进行多维分析展示，辅助定位分析实例异常或业务层面异常。目前覆盖百度内部20多个业务线（包括casio、云分析、网盟、预测、文库、直达号、钱包、风控等），单集群最大100台机器，200个ES节点，每天导入30TB+数据 新浪使用ES 分析处理32亿条实时日志 阿里使用ES 构建挖财自己的日志采集和分析体系 1.3 ElasticSearch对比Solr Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能; Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式； Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供； Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch 第二章 ElasticSearch安装与启动 2.1 下载ES压缩包 ElasticSearch分为Linux和Window版本，基于我们主要学习的是ElasticSearch的Java客户端的使用，所以我们课程中使用的是安装较为简便的Window版本，项目上线后，公司的运维人员会安装Linux版的ES供我们连接使用。 ElasticSearch的官方地址： https://www.elastic.co/products/elasticsearch 在资料中已经提供了下载好的5.6.8的压缩包： 2.2 安装ES服务 Window版的ElasticSearch的安装很简单，类似Window版的Tomcat，解压开即安装完毕，解压后的ElasticSearch的目录结构如下： 修改elasticsearch配置文件：config/elasticsearch.yml，增加以下两句命令： 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 此步为允许elasticsearch跨越访问，如果不安装后面的elasticsearch-head是可以不修改，直接启动。 2.3 启动ES服务 点击ElasticSearch下的bin目录下的elasticsearch.bat启动，控制台显示的日志信息如下： 注意：9300是tcp通讯端口，集群间和TCPClient都执行该端口，9200是http协议的RESTful接口 。 通过浏览器访问ElasticSearch服务器，看到如下返回的json信息，代表服务启动成功： 1注意：ElasticSearch是使用java开发的，且本版本的es需要的jdk版本要是1.8以上，所以安装ElasticSearch之前保证JDK1.8+安装完毕，并正确的配置好JDK环境变量，否则启动ElasticSearch失败。 2.4 安装ES的图形化界面插件 ElasticSearch不同于Solr自带图形化界面，我们可以通过安装ElasticSearch的head插件，完成图形化界面的效果，完成索引数据的查看。安装插件的方式有两种，在线安装和本地安装。本文档采用本地安装方式进行head插件的安装。elasticsearch-5-*以上版本安装head需要安装node和grunt 1）下载head插件：https://github.com/mobz/elasticsearch-head 在资料中已经提供了elasticsearch-head-master插件压缩包： 2）将elasticsearch-head-master压缩包解压到任意目录，但是要和elasticsearch的安装目录区别开 3）下载nodejs：https://nodejs.org/en/download/ 在资料中已经提供了nodejs安装程序： 双击安装程序，步骤截图如下： 安装完毕，可以通过cmd控制台输入：node -v 查看版本号 5）将grunt安装为全局命令 ，Grunt是基于Node.js的项目构建工具 在cmd控制台中输入如下执行命令： 1npm install -g grunt-cli 执行结果如下图： 6）进入elasticsearch-head-master目录启动head，在命令提示符下输入命令： 12&gt;npm install&gt;grunt server 7）打开浏览器，输入 http://localhost:9100，看到如下页面： 如果不能成功连接到es服务，需要修改ElasticSearch的config目录下的配置文件：config/elasticsearch.yml，增加以下两句命令： 12http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 然后重新启动ElasticSearch服务。 第三章 ElasticSearch相关概念(术语) 3.1 概述 Elasticsearch是面向文档(document oriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。Elasticsearch比传统关系型数据库如下： 12Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields 3.2 Elasticsearch核心概念 3.2.1 索引 index 一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索引。 3.2.2 类型 type 在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类/分区，其语义完全由你来定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。 3.2.3 字段Field 相当于是数据表的字段，对文档数据根据不同属性进行的分类标识 3.2.4 映射 mapping mapping是处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分析器、是否被索引等等，这些都是映射里面可以设置的，其它就是处理es里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。 3.2.5 文档 document 一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然，也可以拥有某个订单的一个文档。文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。 在一个index/type里面，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。 3.2.6 接近实时 NRT Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒以内） 3.2.7 集群 cluster 一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群 3.2.8 节点 node 一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。 在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。 3.2.9 分片和复制 shards&amp;replicas 一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因： 1）允许你水平分割/扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，有两个主要原因： 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。 第四章 ElasticSearch的客户端操作 实际开发中，主要有三种方式可以作为elasticsearch服务的客户端： 第一种，elasticsearch-head插件 第二种，使用elasticsearch提供的Restful接口直接访问 第三种，使用elasticsearch提供的API进行访问 4.1 安装Postman工具 Postman中文版是postman这款强大网页调试工具的windows客户端，提供功能强大的Web API &amp; HTTP 请求调试。软件功能非常强大，界面简洁明晰、操作方便快捷，设计得很人性化。Postman中文版能够发送任何类型的HTTP 请求 (GET, HEAD, POST, PUT…)，且可以附带任何数量的参数。 4.1 下载Postman工具 Postman官网：https://www.getpostman.com 课程资料中已经提供了安装包 4.2 注册Postman工具 4.2 使用Postman工具进行Restful接口访问 4.2.1 ElasticSearch的接口语法 1curl -X&lt;VERB&gt; &#39;&lt;PROTOCOL&gt;:&#x2F;&#x2F;&lt;HOST&gt;:&lt;PORT&gt;&#x2F;&lt;PATH&gt;?&lt;QUERY_STRING&gt;&#39; -d &#39;&lt;BODY&gt;&#39; 其中： 参数 解释 VERB 适当的 HTTP 方法 或 谓词 : GET、 POST、 PUT、 HEAD 或者 DELETE。 PROTOCOL http 或者 https（如果你在 Elasticsearch 前面有一个 https 代理） HOST Elasticsearch 集群中任意节点的主机名，或者用 localhost 代表本地机器上的节点。 PORT 运行 Elasticsearch HTTP 服务的端口号，默认是 9200 。 PATH API 的终端路径（例如 _count 将返回集群中文档数量）。Path 可能包含多个组件，例如：_cluster/stats 和 _nodes/stats/jvm 。 QUERY_STRING 任意可选的查询字符串参数 (例如 ?pretty 将格式化地输出 JSON 返回值，使其更容易阅读) BODY 一个 JSON 格式的请求体 (如果请求需要的话) 4.2.2 创建索引index和映射mapping 请求url： 1PUT localhost:9200/blog1 请求体： 12345678910111213141516171819202122232425&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;long&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;not_analyzed&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; &#125; &#125; &#125; &#125;&#125; postman截图： elasticsearch-head查看： ###4.2.3 创建索引后设置Mapping 我们可以在创建索引时设置mapping信息，当然也可以先创建索引然后再设置mapping。 在上一个步骤中不设置maping信息，直接使用put方法创建一个索引，然后设置mapping信息。 请求的url： 1POST http:&#x2F;&#x2F;127.0.0.1:9200&#x2F;blog2&#x2F;hello&#x2F;_mapping 请求体： 1234567891011121314151617181920212223&#123; &quot;hello&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;:&#123; &quot;type&quot;:&quot;long&quot;, &quot;store&quot;:true &#125;, &quot;title&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;store&quot;:true, &quot;index&quot;:true, &quot;analyzer&quot;:&quot;standard&quot; &#125;, &quot;content&quot;:&#123; &quot;type&quot;:&quot;text&quot;, &quot;store&quot;:true, &quot;index&quot;:true, &quot;analyzer&quot;:&quot;standard&quot; &#125; &#125; &#125; &#125; PostMan截图 4.2.4 删除索引index 请求url： 1DELETE localhost:9200/blog1 postman截图： elasticsearch-head查看： 4.2.5 创建文档document 请求url： 1POST localhost:9200/blog1/article/1 请求体： 12345&#123; &quot;id&quot;:1, &quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;, &quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;&#125; postman截图： elasticsearch-head查看： 4.2.6 修改文档document 请求url： 1POST localhost:9200/blog1/article/1 请求体： 12345&#123; &quot;id&quot;:1, &quot;title&quot;:&quot;【修改】ElasticSearch是一个基于Lucene的搜索服务器&quot;, &quot;content&quot;:&quot;【修改】它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;&#125; postman截图： elasticsearch-head查看： 4.2.7 删除文档document 请求url： 1DELETE localhost:9200/blog1/article/1 postman截图： elasticsearch-head查看： 4.2.8 查询文档-根据id查询 请求url： 1GET localhost:9200/blog1/article/1 postman截图： 4.2.9 查询文档-querystring查询 请求url： 1POST localhost:9200/blog1/article/_search 请求体： 12345678&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;default_field&quot;: &quot;title&quot;, &quot;query&quot;: &quot;搜索服务器&quot; &#125; &#125;&#125; postman截图： 注意： 将搜索内容&quot;搜索服务器&quot;修改为&quot;钢索&quot;，同样也能搜索到文档，该原因会在下面讲解中得到答案 12345678&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;default_field&quot;: &quot;title&quot;, &quot;query&quot;: &quot;钢索&quot; &#125; &#125;&#125; 4.2.10 查询文档-term查询 请求url： 1POST localhost:9200/blog1/article/_search 请求体： 1234567&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;搜索&quot; &#125; &#125;&#125; postman截图： 第五章 IK 分词器和ElasticSearch集成使用 5.1 上述查询存在问题分析 在进行字符串查询时，我们发现去搜索&quot;搜索服务器&quot;和&quot;钢索&quot;都可以搜索到数据； 而在进行词条查询时，我们搜索&quot;搜索&quot;却没有搜索到数据； 究其原因是ElasticSearch的标准分词器导致的，当我们创建索引时，字段使用的是标准分词器： 12345678910111213141516171819202122232425&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;long&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;not_analyzed&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; //标准分词器 &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; //标准分词器 &#125; &#125; &#125; &#125;&#125; 例如对 “我是程序员” 进行分词 标准分词器分词效果测试： 1http://127.0.0.1:9200/_analyze?analyzer=standard&amp;pretty=true&amp;text=我是程序员 分词结果： 123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;我&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;程&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;序&quot;, &quot;start_offset&quot; : 3, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;员&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;&lt;IDEOGRAPHIC&gt;&quot;, &quot;position&quot; : 4 &#125; ]&#125; 而我们需要的分词效果是：我、是、程序、程序员 这样的话就需要对中文支持良好的分析器的支持，支持中文分词的分词器有很多，word分词器、庖丁解牛、盘古分词、Ansj分词等，但我们常用的还是下面要介绍的IK分词器。 5.2 IK分词器简介 IKAnalyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出 了3个大版本。最初，它是以开源项目Lucene为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IKAnalyzer3.0则发展为 面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。 IK分词器3.0的特性如下： 1）采用了特有的“正向迭代最细粒度切分算法“，具有60万字/秒的高速处理能力。 2）采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 3）对中英联合支持不是很好,在这方面的处理比较麻烦.需再做一次查询,同时是支持个人词条的优化的词典存储，更小的内存占用。 4）支持用户词典扩展定义。 5）针对Lucene全文检索优化的查询分析器IKQueryParser；采用歧义分析算法优化查询关键字的搜索排列组合，能极大的提高Lucene检索的命中率。 5.3 ElasticSearch集成IK分词器 5.3.1 IK分词器的安装 1）下载地址：https://github.com/medcl/elasticsearch-analysis-ik/releases 课程资料也提供了IK分词器的压缩包： 2）解压，将解压后的elasticsearch文件夹拷贝到elasticsearch-5.6.8\\plugins下，并重命名文件夹为analysis-ik 3）重新启动ElasticSearch，即可加载IK分词器 5.3.2 IK分词器测试 IK提供了两个分词算法ik_smart 和 ik_max_word 其中 ik_smart 为最少切分，ik_max_word为最细粒度划分 我们分别来试一下 1）最小切分：在浏览器地址栏输入地址 1http://127.0.0.1:9200/_analyze?analyzer=ik_smart&amp;pretty=true&amp;text=我是程序员 输出的结果为： 12345678910111213141516171819202122232425&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;我&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;程序员&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125; ]&#125; 2）最细切分：在浏览器地址栏输入地址 1http://127.0.0.1:9200/_analyze?analyzer=ik_max_word&amp;pretty=true&amp;text=我是程序员 输出的结果为： 123456789101112131415161718192021222324252627282930313233343536373839&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;我&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 1, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;是&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;程序员&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;程序&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;员&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 5, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 4 &#125; ]&#125; 5.4 修改索引映射mapping 5.4.1 重建索引 删除原有blog1索引 1DELETE localhost:9200/blog1 创建blog1索引，此时分词器使用ik_max_word 1PUT localhost:9200/blog1 12345678910111213141516171819202122232425&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;long&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;not_analyzed&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot; &#125; &#125; &#125; &#125;&#125; 创建文档 1POST localhost:9200/blog1/article/1 12345&#123; &quot;id&quot;:1, &quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;, &quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;&#125; 5.4.2 再次测试queryString查询 请求url： 1POST localhost:9200/blog1/article/_search 请求体： 12345678&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;default_field&quot;: &quot;title&quot;, &quot;query&quot;: &quot;搜索服务器&quot; &#125; &#125;&#125; postman截图： 将请求体搜索字符串修改为&quot;钢索&quot;，再次查询： 12345678&#123; &quot;query&quot;: &#123; &quot;query_string&quot;: &#123; &quot;default_field&quot;: &quot;title&quot;, &quot;query&quot;: &quot;钢索&quot; &#125; &#125;&#125; postman截图： 5.4.3 再次测试term测试 请求url： 1POST localhost:9200/blog1/article/_search 请求体： 1234567&#123; &quot;query&quot;: &#123; &quot;term&quot;: &#123; &quot;title&quot;: &quot;搜索&quot; &#125; &#125;&#125; postman截图： 第六章 ElasticSearch集群 ​ ES集群是一个 P2P类型(使用 gossip 协议)的分布式系统，除了集群状态管理以外，其他所有的请求都可以发送到集群内任意一台节点上，这个节点可以自己找到需要转发给哪些节点，并且直接跟这些节点通信。所以，从网络架构及服务配置上来说，构建集群所需要的配置极其简单。在 Elasticsearch 2.0 之前，无阻碍的网络下，所有配置了相同 cluster.name 的节点都自动归属到一个集群中。2.0 版本之后，基于安全的考虑避免开发环境过于随便造成的麻烦，从 2.0 版本开始，默认的自动发现方式改为了单播(unicast)方式。配置里提供几台节点的地址，ES 将其视作 gossip router 角色，借以完成集群的发现。由于这只是 ES 内一个很小的功能，所以 gossip router 角色并不需要单独配置，每个 ES 节点都可以担任。所以，采用单播方式的集群，各节点都配置相同的几个节点列表作为 router 即可。 ​ 集群中节点数量没有限制，一般大于等于2个节点就可以看做是集群了。一般处于高性能及高可用方面来考虑一般集群中的节点数量都是3个及3个以上。 6.1 集群的相关概念 6.1.1 集群 cluster 一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集群的名字，来加入这个集群 6.1.2 节点 node 一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此，它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。 在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点，这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。 6.1.3 分片和复制 shards&amp;replicas 一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因： 1）允许你水平分割/扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。 在一个网络/云的环境里，失败随时都可能发生，在某个分片/节点不知怎么的就处于离线状态，或者由于任何原因消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，有两个主要原因： 在分片/节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原/主要（original/primary）分片置于同一节点上是非常重要的。扩展你的搜索量/吞吐量，因为搜索可以在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制）或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你事后不能改变分片的数量。 默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。 6.2 集群的搭建 6.2.1 准备三台elasticsearch服务器 创建elasticsearch-cluster文件夹，在内部复制三个elasticsearch服务 6.2.2 修改每台服务器配置 修改elasticsearch-cluster\\node*\\config\\elasticsearch.yml配置文件 node1节点： 12345678910111213#节点1的配置信息：#集群名称，保证唯一cluster.name: my-elasticsearch#节点名称，必须不一样node.name: node-1#必须为本机的ip地址network.host: 127.0.0.1#服务端口号，在同一机器下必须不一样http.port: 9200#集群间通信端口号，在同一机器下必须不一样transport.tcp.port: 9300#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;] node2节点： 12345678910111213#节点2的配置信息：#集群名称，保证唯一cluster.name: my-elasticsearch#节点名称，必须不一样node.name: node-2#必须为本机的ip地址network.host: 127.0.0.1#服务端口号，在同一机器下必须不一样http.port: 9201#集群间通信端口号，在同一机器下必须不一样transport.tcp.port: 9301#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;] node3节点： 12345678910111213#节点3的配置信息：#集群名称，保证唯一cluster.name: my-elasticsearch#节点名称，必须不一样node.name: node-3#必须为本机的ip地址network.host: 127.0.0.1#服务端口号，在同一机器下必须不一样http.port: 9202#集群间通信端口号，在同一机器下必须不一样transport.tcp.port: 9302#设置集群自动发现机器ip集合discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1:9300&quot;,&quot;127.0.0.1:9301&quot;,&quot;127.0.0.1:9302&quot;] 6.2.3 启动各个节点服务器 双击elasticsearch-cluster\\node*\\bin\\elasticsearch.bat 启动节点1： 启动节点2： 启动节点3： 6.2.4 集群测试 添加索引和映射 1PUT localhost:9200/blog1 12345678910111213141516171819202122232425&#123; &quot;mappings&quot;: &#123; &quot;article&quot;: &#123; &quot;properties&quot;: &#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;long&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;not_analyzed&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;store&quot;: true, &quot;index&quot;:&quot;analyzed&quot;, &quot;analyzer&quot;:&quot;standard&quot; &#125; &#125; &#125; &#125;&#125; 添加文档 1POST localhost:9200/blog1/article/1 12345&#123; &quot;id&quot;:1, &quot;title&quot;:&quot;ElasticSearch是一个基于Lucene的搜索服务器&quot;, &quot;content&quot;:&quot;它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。&quot;&#125; 使用elasticsearch-header查看集群情况","categories":[{"name":"ElasticSearc","slug":"ElasticSearc","permalink":"https://bizhi-1024.github.io/categories/ElasticSearc/"}],"tags":[{"name":"ElasticSearc","slug":"ElasticSearc","permalink":"https://bizhi-1024.github.io/tags/ElasticSearc/"}]},{"title":"Spring Cloud教程","slug":"Spring Cloud 第一天课堂笔记","date":"2021-04-25T07:53:44.600Z","updated":"2021-04-25T08:20:20.885Z","comments":true,"path":"2021/04/25/Spring Cloud 第一天课堂笔记/","link":"","permalink":"https://bizhi-1024.github.io/2021/04/25/Spring%20Cloud%20%E7%AC%AC%E4%B8%80%E5%A4%A9%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1. 系统架构演变概述 目标：了解项目架构的演变历程 小结： 12345graph LR;1[集中式架构] --&gt; 2[垂直拆分]2 --&gt; 3[分布式服务]3 --&gt; 4[SOA面向服务架构]4 --&gt; 5[微服务架构] 2. 微服务架构说明 目标：了解SOA与微服务架构的区别以及说出微服务架构的特点 分析： SOA使用了ESB组件的面向服务架构：ESB自身实现复杂；应用服务粒度较大，所有服务之间的通信都经过ESB会降低通信速度；部署、测试ESB比较麻烦。 小结： 微服务架构：是一套使用小服务或者单一业务来开发单个应用的方式或途径。 微服务架构特点： 单一职责 服务粒度小 面向服务（对外暴露REST api） 服务之间相互独立 与使用ESB的SOA架构的区别：微服务架构没有使用ESB，有服务治理注册中心；业务粒度小。 3. 服务调用方式说明 目标：能够说出服务调用方式种类 小结： RPC：基于socket，速度快，效率高；webservice、dubbo HTTP：基于TCP，封装比较臃肿；对服务和调用方没有任何技术、语言的限定，自由灵活；RESTful，Spring Cloud 4. Spring RestTemplate示例工程导入 目标：了解Spring RestTemplate的应用 分析： 一般情况下有如下三种http客户端工具类包都可以方便的进行http服务调用： httpClient okHttp JDK原生URLConnection spring 提供了RestTemplate的工具类对上述的3种http客户端工具类进行了封装，可在spring项目中使用RestTemplate进行服务调用。 小结： 12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTestpublic class RestTemplateTest &#123; @Autowired private RestTemplate restTemplate; @Test public void test()&#123; String url = &quot;http://localhost/user/8&quot;; //restTemplate可以对json格式字符串进行反序列化 User user = restTemplate.getForObject(url, User.class); System.out.println(user); &#125;&#125; 5. Spring Cloud概述 目标：Spring Cloud整合的组件和版本特征 小结： 整合的组件可以有很多组件；常见的组件有：eureka注册中心，Gateway网关，Ribbon负载均衡，Feign服务调用，Hystrix熔断器。在有需要的时候项目添加对于的启动器依赖即可。 版本特征：以英文单词命名（伦敦地铁站名） 6. 创建微服务工程 目标：创建微服务父工程heima-springcloud、用户服务工程user-service、服务消费工程consumer-demo 分析： 需求：查询数据库中的用户数据并输出到浏览器 父工程heima-springcloud：添加spring boot父坐标和管理其它组件的依赖 用户服务工程user-service：整合mybatis查询数据库中用户数据；提供查询用户服务 服务消费工程consumer-demo：利用查询用户服务获取用户数据并输出到浏览器 小结： 123456789&lt;!-- springCloud --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt;&lt;/dependency&gt; 通过 scope 的import可以继承 spring-cloud-dependencies 工程中的依赖 7. 搭建配置user-service工程 目标：配置user-service工程并能够根据用户id查询数据库中用户 分析： 需求：可以访问http://localhost:9091/user/8输出用户数据 实现步骤： 添加启动器依赖（web、通用Mapper）； 创建启动引导类和配置文件； 修改配置文件中的参数； 编写测试代码（UserMapper，UserService，UserController）； 测试 小结： 添加启动器依赖 123456789101112131415161718&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 通用Mapper启动器 --&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写配置文件 123456789101112server: port: 9091spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/springcloud username: root password: rootmybatis: type-aliases-package: com.itheima.user.pojo 8. 搭建配置consumer-demo工程 目标：编写测试类使用restTemplate访问user-service的路径根据id查询用户 分析： 需求：访问http://localhost:8080/consumer/8 使用RestTemplate获取http://localhost:9091/user/8的数据 实现步骤： 添加启动器依赖； 创建启动引导类（注册RestTemplate）和配置文件； 编写测试代码（ConsumerController中使用restTemplate访问服务获取数据） 测试 小结： 服务管理 如何自动注册和发现 如何实现状态监管 如何实现动态路由 服务如何实现负载均衡 服务如何解决容灾问题 服务如何实现统一配置 上述的问题都可以通过Spring Cloud的各种组件解决。 9. Eureka注册中心说明 目标：说出Eureka的主要功能 小结： Eureka的主要功能是进行服务管理，定期检查服务状态，返回服务地址列表。 10. 搭建eureka-server工程 目标：添加eureka对应依赖和编写引导类搭建eureka服务并可访问eureka服务界面 分析： Eureka是服务注册中心，只做服务注册；自身并不提供服务也不消费服务。可以搭建web工程使用Eureka，可以使用Spring Boot方式搭建。 搭建步骤： 创建工程； 添加启动器依赖； 编写启动引导类（添加Eureka的服务注解）和配置文件； 修改配置文件（端口，应用名称…）； 启动测试 小结： 启动器依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 1234567891011121314server: port: 10086spring: application: name: eureka-servereureka: client: service-url: # eureka 服务地址，如果是集群的话；需要指定其它集群eureka地址 defaultZone: http://127.0.0.1:10086/eureka # 不注册自己 register-with-eureka: false # 不拉取服务 fetch-registry: false 11. 服务注册与发现 目标：将user-service的服务注册到eureka并在consumer-demo中可以根据服务名称调用 分析： 服务注册：在服务提供工程user-service上添加Eureka客户端依赖；自动将服务注册到EurekaServer服务地址列表。 添加依赖； 改造启动引导类；添加开启Eureka客户端发现的注解； 修改配置文件；设置Eureka 服务地址 服务发现：在服务消费工程consumer-demo上添加Eureka客户端依赖；可以使用工具类根据服务名称获取对应的服务地址列表。 添加依赖； 改造启动引导类；添加开启Eureka客户端发现的注解； 修改配置文件；设置Eureka 服务地址； 改造处理器类ConsumerController，可以使用工具类DiscoveryClient根据服务名称获取对应服务地址列表。 小结： 添加Eureka客户端依赖； 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 添加启动引导类注解； 修改配置 1234567spring: application: name: consumer-demoeureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka 12. Eureka Server高可用配置 目标：可以启动两台eureka-server实例；在eureka管理界面看到两个实例 分析： Eureka Server是一个web应用，可以启动多个实例（配置不同端口）保证Eureka Server的高可用。 小结： 高可用配置：将Eureka Server作为一个服务注册到其它Eureka Server，这样多个Eureka Server之间就能够互相发现对方，同步服务，实现Eureka Server集群。 13. Eureka客户端与服务端配置 目标：配置eureka客户端user-service的注册、续约等配置项，配置eureka客户端consumer-demo的获取服务间隔时间；了解失效剔除和自我保护 分析： Eureka客户端工程 user-service 服务提供 服务地址使用ip方式 续约 consumer-demo 服务消费 获取服务地址的频率 Eureka服务端工程 eureka-server 失效剔除 自我保护 小结： user-service 12345678910111213eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka instance: # 更倾向使用ip地址，而不是host名 prefer-ip-address: true # ip地址 ip-address: 127.0.0.1 # 续约间隔，默认30秒 lease-renewal-interval-in-seconds: 5 # 服务失效时间，默认90秒 lease-expiration-duration-in-seconds: 5 consumer-demo 123456eureka: client: service-url: defaultZone: http://127.0.0.1:10086/eureka # 获取服务地址列表间隔时间，默认30秒 registry-fetch-interval-seconds: 10 eureka-server 123456eureka: server: # 服务失效剔除时间间隔，默认60秒 eviction-interval-timer-in-ms: 60000 # 关闭自我保护模式（默认是打开的） enable-self-preservation: false 14. 负载均衡Ribbon简介 目标：描述负载均衡和ribbon的作用 分析： 负载均衡是一个算法，可以通过该算法实现从地址列表中获取一个地址进行服务调用。 在Spring Cloud中提供了负载均衡器：Ribbon 小结： Ribbon提供了轮询、随机两种负载均衡算法（默认是轮询）可以实现从地址列表中使用负载均衡算法获取地址进行服务调用。 15. Ribbon负载均衡应用 目标：配置启动两个用户服务，在consumer-demo中使用服务名实现根据用户id获取用户 分析： 需求：可以使用RestTemplate访问http://user-service/user/8获取服务数据。 可以使用Ribbon负载均衡：在执行RestTemplate发送服务地址请求的时候，使用负载均衡拦截器拦截，根据服务名获取服务地址列表，使用Ribbon负载均衡算法从服务地址列表中选择一个服务地址，访问该地址获取服务数据。 实现步骤： 启动多个user-service实例（9091,9092）； 修改RestTemplate实例化方法，添加负载均衡注解； 修改ConsumerController； 测试 小结： 在实例化RestTemplate的时候使用@LoadBalanced，服务地址直接可以使用服务名。 16. 熔断器Hystrix简介 目标：了解熔断器Hystrix的作用 小结： Hystrix是一个延迟和容错库，用于隔离访问远程服务，防止出现级联失败。 17. 线程隔离&amp;服务降级 目标：了解什么是线程隔离和服务降级 分析： Hystrix解决雪崩效应： 线程隔离：用户请求不直接访问服务，而是使用线程池中空闲的线程访问服务，加速失败判断时间。 服务降级：及时返回服务调用失败的结果，让线程不因为等待服务而阻塞。 小结： consumer-demo中添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 开启熔断 降级逻辑 12345678910111213141516171819202122232425262728293031323334353637@RestController@RequestMapping(&quot;/consumer&quot;)@Slf4j@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; @GetMapping(&quot;/&#123;id&#125;&quot;) //@HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;) @HystrixCommand public String queryById(@PathVariable Long id)&#123; /*String url = &quot;http://localhost:9091/user/&quot;+id; //获取eureka中注册的user-service的实例 List&lt;ServiceInstance&gt; serviceInstances = discoveryClient.getInstances(&quot;user-service&quot;); ServiceInstance serviceInstance = serviceInstances.get(0); url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() + &quot;/user/&quot; + id;*/ String url = &quot;http://user-service/user/&quot; + id; return restTemplate.getForObject(url, String.class); &#125; public String queryByIdFallback(Long id)&#123; log.error(&quot;查询用户信息失败。id：&#123;&#125;&quot;, id); return &quot;对不起，网络太拥挤了！&quot;; &#125; public String defaultFallback()&#123; return &quot;默认提示：对不起，网络太拥挤了！&quot;; &#125;&#125; 修改超时配置 1234567hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 18. 服务熔断演示 目标：了解熔断器工作原理 小结： 可以通过配置服务熔断参数修改默认： 1234567891011hystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 2000 circuitBreaker: errorThresholdPercentage: 50 # 触发熔断错误比例阈值，默认值50% sleepWindowInMilliseconds: 10000 # 熔断后休眠时长，默认值5秒 requestVolumeThreshold: 10 # 熔断触发最小请求次数，默认值是20","categories":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://bizhi-1024.github.io/categories/spring-cloud/"}],"tags":[{"name":"spring cloud","slug":"spring-cloud","permalink":"https://bizhi-1024.github.io/tags/spring-cloud/"}]}],"categories":[{"name":"ElasticSearc","slug":"ElasticSearc","permalink":"https://bizhi-1024.github.io/categories/ElasticSearc/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://bizhi-1024.github.io/categories/spring-cloud/"}],"tags":[{"name":"ElasticSearc","slug":"ElasticSearc","permalink":"https://bizhi-1024.github.io/tags/ElasticSearc/"},{"name":"spring cloud","slug":"spring-cloud","permalink":"https://bizhi-1024.github.io/tags/spring-cloud/"}]}